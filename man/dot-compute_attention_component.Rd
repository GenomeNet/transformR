% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/attention-layers.R
\name{.compute_attention_component}
\alias{.compute_attention_component}
\title{antecedent: Tensor with shape [batch, length, channels]
depth: specifying projection layer depth
filter_width: how wide should the attention component be
padding: must be in: c("VALID", "SAME", "LEFT")}
\usage{
.compute_attention_component(
  antecedent,
  depth,
  filter_width = 1L,
  padding = "SAME",
  name = "c",
  vars_3d_num_heads = 0L
)
}
\description{
antecedent: Tensor with shape [batch, length, channels]
depth: specifying projection layer depth
filter_width: how wide should the attention component be
padding: must be in: c("VALID", "SAME", "LEFT")
}
