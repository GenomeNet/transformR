% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/attention-layers.R
\name{layer_dot_product_attention_1d}
\alias{layer_dot_product_attention_1d}
\title{Input query, key, and value matrices are used to compute dot product
attention. (Vaswani et al. 2017)
q: a Tensor with shape [batch, length_q,  depth_k]
k: a Tensor with shape [batch, length_kv, depth_k]
v: a Tensor with shape [batch, length_kv, depth_v]}
\usage{
layer_dot_product_attention_1d(
  q,
  k,
  v,
  bias = NULL,
  dropout = 0,
  name = "dot_product_attention"
)
}
\description{
Input query, key, and value matrices are used to compute dot product
attention. (Vaswani et al. 2017)
q: a Tensor with shape [batch, length_q,  depth_k]
k: a Tensor with shape [batch, length_kv, depth_k]
v: a Tensor with shape [batch, length_kv, depth_v]
}
