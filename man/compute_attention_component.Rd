% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/attention-layers.R, R/attention-utils.R
\name{compute_attention_component}
\alias{compute_attention_component}
\title{antecedent: Tensor with shape [batch, length, channels]
depth: specifying projection layer depth
filter_width: how wide should the attention component be
padding: must be in: c("VALID", "SAME", "LEFT")}
\usage{
compute_attention_component(
  antecedent,
  depth,
  filter_width = 1L,
  padding = "valid",
  name = "c",
  vars_3d_num_heads = 0L
)

compute_attention_component(
  antecedent,
  depth,
  filter_width = 1L,
  padding = "valid",
  name = "c",
  vars_3d_num_heads = 0L
)
}
\description{
antecedent: Tensor with shape [batch, length, channels]
depth: specifying projection layer depth
filter_width: how wide should the attention component be
padding: must be in: c("VALID", "SAME", "LEFT")

antecedent: Tensor with shape [batch, length, channels]
depth: specifying projection layer depth
filter_width: how wide should the attention component be
padding: must be in: c("valid", "same", "left")
}
